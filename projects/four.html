<!DOCTYPE html>
<html lang="es">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Imaging Sciences Laboratory: Applied Research in Academic, Industrial, and Governmental Contexts
    </title>
    <link rel="stylesheet" href="../styles.css"> <!-- Enlace a archivo de estilos CSS -->

    <link href="https://cdn.jsdelivr.net/npm/bootstrap@5.0.2/dist/css/bootstrap.min.css" rel="stylesheet" integrity="sha384-EVSTQN3/azprG1Anm3QDgpJLIm9Nao0Yz1ztcQTwFspd3yD65VohhpuuCOmLASjC" crossorigin="anonymous">

</head>
<body>
    <header class="header bg-primary">
        <h1>Imaging Sciences Laboratory</h1>
    </header>
     <!-- NAvBar -->
     <nav class="navbar navbar-expand-lg navbar-dark bg-dark sticky-top">
        <div class="container-fluid">
          <a class="navbar-brand" href="#">ISL</a>
          <button class="navbar-toggler" type="button" data-bs-toggle="collapse" data-bs-target="#navbarSupportedContent" aria-controls="navbarSupportedContent" aria-expanded="false" aria-label="Toggle navigation">
            <span class="navbar-toggler-icon"></span>
          </button>
          <div class="collapse navbar-collapse" id="navbarSupportedContent">
            <ul class="navbar-nav me-auto mb-2 mb-lg-0">
              <li class="nav-item">
                <a class="nav-link"  href="../index.html">Home</a>
              </li>
              <li class="nav-item dropdown">
                <a class="nav-link dropdown-toggle" href="#" id="navbarDropdown" role="button" data-bs-toggle="dropdown" aria-expanded="true">
                  Research
                </a>
                <ul class="dropdown-menu" aria-labelledby="navbarDropdown">
                  <li><a class="dropdown-item  " aria-current="page" href="./one.html">Project one</a></li>
                  <li><a class="dropdown-item " href="./two.html">Project</a></li>
                  <li><a class="dropdown-item " href="./three.html">Project</a></li>
                  <li><a class="dropdown-item active" href="./four.html">Project</a></li>
                  <li><a class="dropdown-item" href="./five.html">Project</a></li>
                  
                </ul>
              </li>
            </ul>
          </div>
        </div>
      </nav>
     <!-- NavBar end -->
     <nav aria-label="breadcrumb">
        <ol class="breadcrumb">
          <li class="breadcrumb-item"><a href="#">Home</a></li>
          <li class="breadcrumb-item active" aria-current="page">Project four</li>
        </ol>
      </nav>
  
    <main>
        <article>
            <h2>Automated personnel digital twinning in industrial workplaces.</h2>
            <img src="../imgs/workers.png" class="responsive-image" alt="imagen">

                    <p>
                        
                        Virtualized work environments facilitate testing and simulating actual and hypothetical scenarios, feeding relevant information back into the actual environment. This is valuable in the context of data-driven Industry 4.0, where generalized requirements concerning a more thorough analysis of workersâ€™ activities in several settings are required. This project aims to extract video-based information about personnel activities in their workplaces, aiming at ergonomic risk assessment and prevention, safety conditions, and overall monitoring. The extracted parameters inform ergonomists or managers regarding situations or contexts that require intervention. (DOI: 10.1109/ICECET55527.2022.9872882).</p>
                        <p>Digital twin technology is designed to use real world data together with simulation programs to understand or predict how a process or activity is being performed.
                        This technology arose in the last decade in several industrial contexts, mostly focused on devices, facilities and manufacturing, and only very recently to twinning human behavior.
                        This paper describes an applied study on digital twinning of workers within complex and varying industrial settings, using the recently introduced VIBE neural network.
                        VIBE comprises a two-stage pipeline of neural network blocks (NNB), where the first stage determines detection and tracking, while the second stage performs 2D-to-3D human model mapping.
                        The first stage allows using three different NNB combinations, namely Mask R-CNN \& SORT, YOLO \& {SORT}, and STAF.
                        In this work, we focus on the influence of each NNB on the second stage and the final output using state-of-the-art performance metrics.
                        Mask R-CNN \& SORT provided a multi-object tracking accuracy (MOTA) of 87,2\%, while STAF obtained a MOTA of 88,5\% and the best performance with occlusions in the final 2D-to-3D human rendering.
                        These results pave the road for new developments in real-time complex digital twinning and workplace virtualization, in which human activities are an essential part.</p> 
                        
                </li>
        
            

        </article>

        
    </main>

    <footer>
        <p>&copy; 2023 Imaging Sciences Laboratory: <br> Applied Research in Academic, Industrial, and Governmental Contexts.<br> All right reserved.</p>
    </footer>

    <script src="https://cdn.jsdelivr.net/npm/bootstrap@5.0.2/dist/js/bootstrap.bundle.min.js" integrity="sha384-MrcW6ZMFYlzcLA8Nl+NtUVF0sA7MsXsP1UyJoMp4YLEuNSfAP+JcXn/tWtIaxVXM" crossorigin="anonymous"></script>

</body>
</html>
